/*
 * CXL Firewall Userspace Control Plane
 *
 * This module loads and manages the CXL firewall eBPF coprocessor,
 * configures ATS policies, manages shadow cache state, and provides
 * fault injection capabilities for kernel fuzzing.
 *
 * Copyright (c) 2025 Drywall Project
 *
 * This work is licensed under the terms of the GNU GPL, version 2. See the
 * COPYING file in the top-level directory.
 */

#include "qemu/osdep.h"
#include "qemu/error-report.h"
#include "qemu/log.h"
#include "qapi/error.h"
#include "hw/cxl/cxl.h"
#include "hw/cxl/cxl_device.h"
#include "cxl_firewall.h"

#include <bpf/libbpf.h>
#include <bpf/bpf.h>

/* eBPF skeleton (generated by bpftool) */
#ifdef CONFIG_LIBBPF
#include "cxl_firewall.bpf.skeleton.h"
#endif

#define MAX_POLICIES 256
#define CACHELINE_SIZE 64

struct CXLFirewallState {
    /* eBPF program state */
#ifdef CONFIG_LIBBPF
    struct cxl_firewall_bpf *skel;
    int shadow_cache_fd;
    int ats_policy_fd;
    int event_ringbuf_fd;
    int fault_config_fd;
    int stats_fd;
    int ownership_fd;
#endif

    /* Configuration */
    bool enabled;
    bool fault_injection_enabled;
    uint32_t num_policies;

    /* Statistics */
    uint64_t total_transactions;
    uint64_t policy_violations;
    uint64_t faults_injected;
};

/* Global firewall instance */
static struct CXLFirewallState *g_firewall_state = NULL;

/* Initialize CXL firewall eBPF coprocessor */
CXLFirewallState *cxl_firewall_init(Error **errp)
{
#ifndef CONFIG_LIBBPF
    error_setg(errp, "CXL firewall requires libbpf support");
    return NULL;
#else
    struct CXLFirewallState *state;
    int err;

    state = g_new0(struct CXLFirewallState, 1);

    /* Load and verify eBPF program */
    state->skel = cxl_firewall_bpf__open();
    if (!state->skel) {
        error_setg(errp, "Failed to open CXL firewall eBPF skeleton");
        goto fail;
    }

    /* Load eBPF program into kernel */
    err = cxl_firewall_bpf__load(state->skel);
    if (err) {
        error_setg(errp, "Failed to load CXL firewall eBPF program: %d", err);
        goto fail_destroy;
    }

    /* Attach eBPF program (if using tracepoints) */
    err = cxl_firewall_bpf__attach(state->skel);
    if (err) {
        error_setg(errp, "Failed to attach CXL firewall eBPF program: %d", err);
        goto fail_destroy;
    }

    /* Get file descriptors for maps */
    state->shadow_cache_fd = bpf_map__fd(state->skel->maps.shadow_cache_map);
    state->ats_policy_fd = bpf_map__fd(state->skel->maps.ats_policy_map);
    state->event_ringbuf_fd = bpf_map__fd(state->skel->maps.event_ringbuf);
    state->fault_config_fd = bpf_map__fd(state->skel->maps.fault_config_map);
    state->stats_fd = bpf_map__fd(state->skel->maps.stats_map);
    state->ownership_fd = bpf_map__fd(state->skel->maps.ownership_map);

    if (state->shadow_cache_fd < 0 || state->ats_policy_fd < 0 ||
        state->event_ringbuf_fd < 0 || state->fault_config_fd < 0 ||
        state->stats_fd < 0 || state->ownership_fd < 0) {
        error_setg(errp, "Failed to get BPF map file descriptors");
        goto fail_detach;
    }

    state->enabled = true;
    state->fault_injection_enabled = false;
    state->num_policies = 0;

    info_report("CXL firewall eBPF coprocessor initialized successfully");

    g_firewall_state = state;
    return state;

fail_detach:
    cxl_firewall_bpf__detach(state->skel);
fail_destroy:
    cxl_firewall_bpf__destroy(state->skel);
fail:
    g_free(state);
    return NULL;
#endif /* CONFIG_LIBBPF */
}

/* Cleanup CXL firewall */
void cxl_firewall_cleanup(CXLFirewallState *state)
{
#ifdef CONFIG_LIBBPF
    if (!state)
        return;

    if (state->skel) {
        cxl_firewall_bpf__detach(state->skel);
        cxl_firewall_bpf__destroy(state->skel);
    }

    g_free(state);
    g_firewall_state = NULL;

    info_report("CXL firewall eBPF coprocessor cleaned up");
#endif
}

/* Add ATS exclusivity policy for a memory region */
int cxl_firewall_add_policy(CXLFirewallState *state, uint64_t start_addr,
                            uint64_t end_addr, uint32_t policy_flags,
                            bool allow_exclusive, bool require_shadow)
{
#ifndef CONFIG_LIBBPF
    return -1;
#else
    struct ats_policy policy = {
        .start_addr = start_addr,
        .end_addr = end_addr,
        .policy_flags = policy_flags,
        .device_mask = 0,  /* 0 = all devices */
        .allow_exclusive = allow_exclusive ? 1 : 0,
        .require_shadow = require_shadow ? 1 : 0,
        .priority = 0,
    };
    uint32_t key = state->num_policies;

    if (key >= MAX_POLICIES) {
        error_report("CXL firewall: Maximum number of policies reached");
        return -1;
    }

    if (bpf_map_update_elem(state->ats_policy_fd, &key, &policy, BPF_ANY) < 0) {
        error_report("CXL firewall: Failed to add policy");
        return -1;
    }

    state->num_policies++;

    qemu_log_mask(LOG_UNIMP, "CXL firewall: Added policy for region 0x%lx-0x%lx "
                  "(exclusive=%d, shadow=%d)\n",
                  start_addr, end_addr, allow_exclusive, require_shadow);

    return 0;
#endif
}

/* Configure fault injection */
int cxl_firewall_configure_fault_injection(CXLFirewallState *state,
                                           bool enabled, uint32_t inject_rate,
                                           uint32_t fault_type,
                                           uint32_t target_device,
                                           uint64_t target_addr_start,
                                           uint64_t target_addr_end)
{
#ifndef CONFIG_LIBBPF
    return -1;
#else
    struct fault_injection_config config = {
        .enabled = enabled ? 1 : 0,
        .inject_rate = inject_rate,
        .fault_type = fault_type,
        .target_device = target_device,
        .target_addr_start = target_addr_start,
        .target_addr_end = target_addr_end,
    };
    uint32_t key = 0;

    if (bpf_map_update_elem(state->fault_config_fd, &key, &config, BPF_ANY) < 0) {
        error_report("CXL firewall: Failed to configure fault injection");
        return -1;
    }

    state->fault_injection_enabled = enabled;

    info_report("CXL firewall: Fault injection %s (rate=1/%d, type=%d)",
                enabled ? "enabled" : "disabled", inject_rate, fault_type);

    return 0;
#endif
}

/* Check if exclusive access is allowed for an address */
bool cxl_firewall_check_exclusive_access(CXLFirewallState *state, uint64_t addr,
                                         uint32_t device_id, uint32_t ats_flags)
{
#ifndef CONFIG_LIBBPF
    return true;  /* No firewall - allow everything */
#else
    if (!state || !state->enabled)
        return true;

    /* This is a simplified check - the actual enforcement happens in eBPF */
    /* Here we just provide a quick path for QEMU to check before invoking eBPF */

    /* Iterate through policies to find matching region */
    for (uint32_t i = 0; i < state->num_policies; i++) {
        struct ats_policy policy;

        if (bpf_map_lookup_elem(state->ats_policy_fd, &i, &policy) < 0)
            continue;

        if (addr >= policy.start_addr && addr < policy.end_addr) {
            /* Check if exclusive access is allowed */
            if (!policy.allow_exclusive && (ats_flags & 0x4))
                return false;

            /* Check device mask */
            if (policy.device_mask && !(policy.device_mask & (1 << device_id)))
                return false;

            return true;
        }
    }

    /* No policy found - allow by default */
    return true;
#endif
}

/* Create shadow backup before granting exclusive access */
int cxl_firewall_create_shadow(CXLFirewallState *state, uint64_t addr,
                               uint32_t device_id, uint32_t ats_flags,
                               uint8_t *data, size_t len)
{
#ifndef CONFIG_LIBBPF
    return 0;  /* No firewall - no shadow needed */
#else
    struct shadow_cacheline shadow = {0};
    uint64_t cl_addr = addr & ~(CACHELINE_SIZE - 1);

    if (!state || !state->enabled || len != CACHELINE_SIZE)
        return -1;

    shadow.addr = cl_addr;
    shadow.timestamp = qemu_clock_get_ns(QEMU_CLOCK_VIRTUAL);
    shadow.device_id = device_id;
    shadow.ats_flags = ats_flags | 0x10;  /* ATS_FLAG_SHADOWED */
    shadow.state = 2;  /* CXL_STATE_EXCLUSIVE */
    shadow.version = 1;

    memcpy(shadow.data, data, CACHELINE_SIZE);

    /* Compute simple checksum (CRC64 computed in eBPF) */
    uint64_t checksum = 0;
    for (size_t i = 0; i < CACHELINE_SIZE; i++) {
        checksum ^= data[i];
    }
    memcpy(shadow.checksum, &checksum, sizeof(uint64_t));

    if (bpf_map_update_elem(state->shadow_cache_fd, &cl_addr, &shadow, BPF_ANY) < 0) {
        error_report("CXL firewall: Failed to create shadow for addr 0x%lx", cl_addr);
        return -1;
    }

    qemu_log_mask(LOG_UNIMP, "CXL firewall: Created shadow for cacheline 0x%lx "
                  "(device=%d)\n", cl_addr, device_id);

    return 0;
#endif
}

/* Restore from shadow when device fails */
int cxl_firewall_restore_from_shadow(CXLFirewallState *state, uint64_t addr,
                                    uint8_t *data_out, size_t len)
{
#ifndef CONFIG_LIBBPF
    return -1;
#else
    struct shadow_cacheline shadow;
    uint64_t cl_addr = addr & ~(CACHELINE_SIZE - 1);

    if (!state || !state->enabled || len != CACHELINE_SIZE)
        return -1;

    if (bpf_map_lookup_elem(state->shadow_cache_fd, &cl_addr, &shadow) < 0) {
        qemu_log_mask(LOG_GUEST_ERROR, "CXL firewall: No shadow found for addr 0x%lx\n",
                      cl_addr);
        return -1;
    }

    /* Verify checksum */
    uint64_t checksum = 0;
    for (size_t i = 0; i < CACHELINE_SIZE; i++) {
        checksum ^= shadow.data[i];
    }
    uint64_t stored_checksum;
    memcpy(&stored_checksum, shadow.checksum, sizeof(uint64_t));

    if (checksum != stored_checksum) {
        error_report("CXL firewall: Shadow checksum mismatch for addr 0x%lx", cl_addr);
        return -2;
    }

    memcpy(data_out, shadow.data, CACHELINE_SIZE);

    qemu_log_mask(LOG_UNIMP, "CXL firewall: Restored cacheline 0x%lx from shadow\n",
                  cl_addr);

    return 0;
#endif
}

/* Handle device going offline - restore all exclusive cachelines */
int cxl_firewall_device_offline(CXLFirewallState *state, uint32_t device_id)
{
#ifndef CONFIG_LIBBPF
    return 0;
#else
    uint64_t addr;
    uint32_t owner_id;
    int count = 0;

    if (!state || !state->enabled)
        return 0;

    /* Iterate through ownership map and restore all cachelines owned by this device */
    /* Note: This requires iterating the map, which is not efficient but necessary */

    info_report("CXL firewall: Device %d went offline, restoring exclusive cachelines",
                device_id);

    /* In a real implementation, we would need to maintain a per-device index
     * or iterate through the entire ownership map. For now, this is a placeholder. */

    return count;
#endif
}

/* Get firewall statistics */
int cxl_firewall_get_stats(CXLFirewallState *state, CXLFirewallStats *stats_out)
{
#ifndef CONFIG_LIBBPF
    return -1;
#else
    struct cxl_statistics stats;
    uint32_t key = 0;

    if (!state || !stats_out)
        return -1;

    if (bpf_map_lookup_elem(state->stats_fd, &key, &stats) < 0) {
        error_report("CXL firewall: Failed to read statistics");
        return -1;
    }

    stats_out->total_transactions = stats.total_transactions;
    stats_out->exclusive_grants = stats.exclusive_grants;
    stats_out->exclusive_revokes = stats.exclusive_revokes;
    stats_out->policy_violations = stats.policy_violations;
    stats_out->shadow_creates = stats.shadow_creates;
    stats_out->shadow_restores = stats.shadow_restores;
    stats_out->faults_injected = stats.faults_injected;

    return 0;
#endif
}

/* Get global firewall instance */
CXLFirewallState *cxl_firewall_get_global(void)
{
    return g_firewall_state;
}
